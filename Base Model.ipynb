{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras.models import Model\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from numpy import array\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers.core import Reshape\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv1D, LSTM, GRU, Bidirectional, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "movie_reviews.isnull().values.any()\n",
    "\n",
    "movie_reviews.shape\n",
    "movie_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2c0d4004388>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='sentiment', data=movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "X = []\n",
    "sentences = list(movie_reviews['review'])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "    \n",
    "y = movie_reviews['sentiment']\n",
    "\n",
    "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          9254700   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 10001     \n",
      "=================================================================\n",
      "Total params: 9,264,701\n",
      "Trainable params: 10,001\n",
      "Non-trainable params: 9,254,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/6\n",
      "32000/32000 [==============================] - 1s 44us/step - loss: 0.5980 - acc: 0.6764 - val_loss: 0.5310 - val_acc: 0.7333\n",
      "Epoch 2/6\n",
      "32000/32000 [==============================] - 1s 38us/step - loss: 0.4944 - acc: 0.7643 - val_loss: 0.5187 - val_acc: 0.7421\n",
      "Epoch 3/6\n",
      "32000/32000 [==============================] - 1s 38us/step - loss: 0.4569 - acc: 0.7868 - val_loss: 0.5150 - val_acc: 0.7469\n",
      "Epoch 4/6\n",
      "32000/32000 [==============================] - 1s 38us/step - loss: 0.4333 - acc: 0.8006 - val_loss: 0.5257 - val_acc: 0.7429\n",
      "Epoch 5/6\n",
      "32000/32000 [==============================] - 1s 38us/step - loss: 0.4207 - acc: 0.8088 - val_loss: 0.5296 - val_acc: 0.7448\n",
      "Epoch 6/6\n",
      "32000/32000 [==============================] - 1s 39us/step - loss: 0.4086 - acc: 0.8141 - val_loss: 0.5357 - val_acc: 0.7408\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 43us/step\n",
      "Test Score: 53.67218564033508\n",
      "Test Accuracy: 73.90999794006348\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0]*100)\n",
    "print(\"Test Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          9254700   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 96, 128)           64128     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,318,957\n",
      "Trainable params: 64,257\n",
      "Non-trainable params: 9,254,700\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/6\n",
      "32000/32000 [==============================] - 19s 589us/step - loss: 0.5207 - acc: 0.7383 - val_loss: 0.4038 - val_acc: 0.8195\n",
      "Epoch 2/6\n",
      "32000/32000 [==============================] - 19s 583us/step - loss: 0.3743 - acc: 0.8346 - val_loss: 0.3723 - val_acc: 0.8305\n",
      "Epoch 3/6\n",
      "32000/32000 [==============================] - 20s 616us/step - loss: 0.3263 - acc: 0.8611 - val_loss: 0.3633 - val_acc: 0.8372\n",
      "Epoch 4/6\n",
      "32000/32000 [==============================] - 19s 592us/step - loss: 0.2882 - acc: 0.8817 - val_loss: 0.3658 - val_acc: 0.8355\n",
      "Epoch 5/6\n",
      "32000/32000 [==============================] - 19s 597us/step - loss: 0.2589 - acc: 0.8967 - val_loss: 0.3709 - val_acc: 0.8334\n",
      "Epoch 6/6\n",
      "32000/32000 [==============================] - 19s 586us/step - loss: 0.2231 - acc: 0.9167 - val_loss: 0.3434 - val_acc: 0.8454\n",
      "10000/10000 [==============================] - 2s 230us/step\n",
      "Test Score: 34.128243350982665\n",
      "Test Accuracy: 84.92000102996826\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0]*100)\n",
    "print(\"Test Accuracy:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          9254700   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 9,372,077\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 9,254,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/6\n",
      "32000/32000 [==============================] - 80s 3ms/step - loss: 0.5601 - acc: 0.7053 - val_loss: 0.5069 - val_acc: 0.7654\n",
      "Epoch 2/6\n",
      "32000/32000 [==============================] - 84s 3ms/step - loss: 0.4503 - acc: 0.7879 - val_loss: 0.4321 - val_acc: 0.8140\n",
      "Epoch 3/6\n",
      "32000/32000 [==============================] - 102s 3ms/step - loss: 0.3965 - acc: 0.8219 - val_loss: 0.4231 - val_acc: 0.8033\n",
      "Epoch 4/6\n",
      "32000/32000 [==============================] - 100s 3ms/step - loss: 0.3663 - acc: 0.8360 - val_loss: 0.3566 - val_acc: 0.8444\n",
      "Epoch 5/6\n",
      "32000/32000 [==============================] - 70s 2ms/step - loss: 0.3420 - acc: 0.8500 - val_loss: 0.3454 - val_acc: 0.8511\n",
      "Epoch 6/6\n",
      "32000/32000 [==============================] - 72s 2ms/step - loss: 0.3276 - acc: 0.8568 - val_loss: 0.3454 - val_acc: 0.8514\n",
      "10000/10000 [==============================] - 9s 857us/step\n",
      "Test Score [LSTM]: 34.737881016731265\n",
      "Test Accuracy [LSTM]: 84.35999751091003\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(128))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score [LSTM]:\", score[0]*100)\n",
    "print(\"Test Accuracy [LSTM]:\", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          9254700   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 100, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 9,582,253\n",
      "Trainable params: 327,553\n",
      "Non-trainable params: 9,254,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/6\n",
      "32000/32000 [==============================] - 80s 3ms/step - loss: 0.5072 - acc: 0.7460 - val_loss: 0.4197 - val_acc: 0.8033\n",
      "Epoch 2/6\n",
      "32000/32000 [==============================] - 81s 3ms/step - loss: 0.3940 - acc: 0.8206 - val_loss: 0.4799 - val_acc: 0.7604\n",
      "Epoch 3/6\n",
      "32000/32000 [==============================] - 80s 3ms/step - loss: 0.3414 - acc: 0.8497 - val_loss: 0.3447 - val_acc: 0.8439\n",
      "Epoch 4/6\n",
      "32000/32000 [==============================] - 81s 3ms/step - loss: 0.3068 - acc: 0.8691 - val_loss: 0.3506 - val_acc: 0.8403\n",
      "Epoch 5/6\n",
      "32000/32000 [==============================] - 81s 3ms/step - loss: 0.2611 - acc: 0.8914 - val_loss: 0.3795 - val_acc: 0.8366\n",
      "Epoch 6/6\n",
      "32000/32000 [==============================] - 84s 3ms/step - loss: 0.2292 - acc: 0.9051 - val_loss: 0.3783 - val_acc: 0.8441\n",
      "10000/10000 [==============================] - 8s 810us/step\n",
      "Test Score [conv1D + LSTM]: 0.36984034317731856\n",
      "Test Accuracy [conv1D + LSTM]: 0.8460000157356262\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score [conv1D + LSTM]:\", score[0])\n",
    "print(\"Test Accuracy [conv1D + LSTM]:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 100, 100)          9254700   \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 100, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               197376    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 9,516,461\n",
      "Trainable params: 261,761\n",
      "Non-trainable params: 9,254,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/6\n",
      "32000/32000 [==============================] - 79s 2ms/step - loss: 0.5237 - acc: 0.7281 - val_loss: 0.4099 - val_acc: 0.8104\n",
      "Epoch 2/6\n",
      "32000/32000 [==============================] - 76s 2ms/step - loss: 0.3808 - acc: 0.8303 - val_loss: 0.3627 - val_acc: 0.8389\n",
      "Epoch 3/6\n",
      "32000/32000 [==============================] - 76s 2ms/step - loss: 0.3344 - acc: 0.8524 - val_loss: 0.3413 - val_acc: 0.8510\n",
      "Epoch 4/6\n",
      "32000/32000 [==============================] - 76s 2ms/step - loss: 0.2879 - acc: 0.8772 - val_loss: 0.3425 - val_acc: 0.8526\n",
      "Epoch 5/6\n",
      "32000/32000 [==============================] - 74s 2ms/step - loss: 0.2360 - acc: 0.9027 - val_loss: 0.4008 - val_acc: 0.8346\n",
      "Epoch 6/6\n",
      "32000/32000 [==============================] - 75s 2ms/step - loss: 0.1904 - acc: 0.9240 - val_loss: 0.4706 - val_acc: 0.8044\n",
      "10000/10000 [==============================] - 7s 699us/step\n",
      "Test Score [conv1D + GRU]: 0.4702037090539932\n",
      "Test Accuracy [conv1D + GRU]: 0.8021000027656555\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Bidirectional(GRU(128)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score [conv1D + GRU]:\", score[0])\n",
    "print(\"Test Accuracy [conv1D + GRU]:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPROVEMENT(COMPLEX MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 100, 100)          9254700   \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 100, 512)          256512    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 50, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 50, 256)           655616    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 25, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 25, 256)           327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 12, 256)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 10,889,261\n",
      "Trainable params: 1,634,561\n",
      "Non-trainable params: 9,254,700\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/6\n",
      "32000/32000 [==============================] - 189s 6ms/step - loss: 0.5396 - acc: 0.7078 - val_loss: 0.4023 - val_acc: 0.8134\n",
      "Epoch 2/6\n",
      "32000/32000 [==============================] - 192s 6ms/step - loss: 0.3792 - acc: 0.8301 - val_loss: 0.3670 - val_acc: 0.8361\n",
      "Epoch 3/6\n",
      "32000/32000 [==============================] - 186s 6ms/step - loss: 0.3098 - acc: 0.8670 - val_loss: 0.3293 - val_acc: 0.8555\n",
      "Epoch 4/6\n",
      "32000/32000 [==============================] - 239s 7ms/step - loss: 0.2515 - acc: 0.8961 - val_loss: 0.3537 - val_acc: 0.8561\n",
      "Epoch 5/6\n",
      "32000/32000 [==============================] - 280s 9ms/step - loss: 0.1782 - acc: 0.9293 - val_loss: 0.3603 - val_acc: 0.8470\n",
      "Epoch 6/6\n",
      "32000/32000 [==============================] - 235s 7ms/step - loss: 0.0994 - acc: 0.9630 - val_loss: 0.5636 - val_acc: 0.8314\n",
      "10000/10000 [==============================] - 20s 2ms/step\n",
      "Test Score [conv1D + LSTM]: 0.5387560107707977\n",
      "Test Accuracy [conv1D + LSTM]: 0.8374999761581421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(512, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(256, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Conv1D(256, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size = 2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score [conv1D + LSTM]:\", score[0])\n",
    "print(\"Test Accuracy [conv1D + LSTM]:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
